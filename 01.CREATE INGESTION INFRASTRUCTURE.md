



在本章中，您将在AWS内设置基础设施，以专注于架构的 ingestion、流和转换部分。

创建了Amazon Kinesis数据流，它作为出租车车队创建的事件的短期流存储。然后你开始在Kinesis数据流中生成一组历史性的出租车行程。

Kinesis数据流(beam-workshop)起到缓冲的作用，将生产者和消费者分离开来。对于分析流数据的架构来说，通过流存储将生产者与消费者分离开来是一种常见的模式。通过这种方式，体系结构变得更加健壮。生产者和消费者可以独立伸缩，生产者仍然可以将事件持久化到数据流中，即使消费者当前遇到操作问题或消费应用程序需要更新。

此外，Amazon Kinesis Data Firehose (beam-workshop-s3)用于在数据加载到数据湖、数据存储和分析工具之前对数据执行任何丰富和转换。这些数据转换是通过调用AWS Lambda来执行的，AWS Lambda是一个没有服务器的平台，运行代码时不需要供应或管理服务器。对于这种架构，我们将转换后的数据存储到Amazon S3中，这样它就可以被我们的Beam管道读取。

这个基础结构还允许您在将来试验和采用新技术。多个独立的应用程序可以同时使用存储在Kinesis数据流中的数据。然后，您可以测试现有应用程序的新版本如何使用生产流量副本执行。但是您也可以引入不同的工具和技术堆栈来分析数据，同样不会影响现有的生产应用程序。



#### CREATE A KINESIS DATA STREAM



首先创建一个Kinesis数据流。

1. 导航 [Kinesis Console](https://console.amazonaws.cn/kinesis)

2. 如果显示，向上按开始在服务欢迎对话框

3. 选择创建数据流，导航到Amazon Kinesis数据流服务:

![image-20201115102655589](/Users/wjianye/Desktop/BeamOnKDA/image/image-20201115102655589.png)

4. 选择`beam-workshop`作为运动流的名称

5. 输入4作为分片的数量。

![image-20201115102944504](/Users/wjianye/Desktop/BeamOnKDA/image/image-20201115102944504.png)





Select **Create Kinesis stream** at the bottom of the page

![image-20201115103208784](/Users/wjianye/Desktop/BeamOnKDA/image/image-20201115103208784.png)

8. 现在我们已经准备好创建Firehose



#### CREATE A FIREHOSE DELIVERY STREAM

接下来，您将创建Amazon Kinesis Data Firehose交付流，以允许转换和丰富源数据，最终将其存储到S3 bucket中。交付流将使用先前创建的数据流中的数据。交付流还通过已经为实验室预先创建的AWS Lambda函数，丰富了持久化到Amazon S3的事件。

持久化在运动流中的每个事件都会在事件元数据中自动分配一个近似的到达时间戳。Lambda函数只是在将元数据写入Amazon S3时将大约到达时间戳添加到消息的有效负载中。



创建 Lambda函数，它的名字是*EnrichEventsLambda*

```javascript
function enrichPayload(record) {
  const payload = JSON.parse(
    Buffer.from(record.data, "base64").toString("utf8")
  );
  const timestamp = new Date(
    record.kinesisRecordMetadata.approximateArrivalTimestamp
  ).toISOString();

  const enrichedPayload = Object.assign(
    { approximate_arrival_timestamp: timestamp },
    payload
  );

  return Buffer.from(JSON.stringify(enrichedPayload) + "\n").toString("base64");
}

```



通过这种方式，流和批处理管道可以引用相同的时间戳，所以我们可以得到相同的结果批处理和流管道。按照本章的步骤创建交付流程。



#### NAME AND SOURCE

要开始创建一个Firehose交付流，您需要选择一个名称

1. 导航到 [Amazon Kinesis Data Firehose](https://console.amazonaws.cn/firehose/) 控制台并选择 Create delivery stream

2. 选择`beam-workshop-s3`作为交付流名称

3. 选择Kinesis数据流作为源

4. 在下拉菜单中选择beam-workshop作为运动数据流源

选择Next移动到流程记录屏幕。

![image-20201115110152744](/Users/wjianye/Desktop/BeamOnKDA/image/image-20201115110152744.png)

#### PROCESS RECORDS

然后附加Lambda函数来充实记录

1. 在数据转换下选择启用

2. 在Lambda函数的下拉列表中，选择名称包含EnrichEventsLambda的Lambda函数

3. 保持记录格式转换为禁用状态

4. 选择Next移动到“选择目标”屏幕上。

![image-20201115121746314](/Users/wjianye/Desktop/BeamOnKDA/image/image-20201115121746314.png)













### CHOOSE A DESTINATION

在此步骤中，您将为转换后的记录选择目的地。

1. 选择Amazon S3作为目标类型

2. 对于S3 Bucket名，选择预定义的S3 Bucket，它的名称包含历史记录

3. 对于前缀，输入history -trip-events/，以便在Amazon S3中容易识别所有转换后的记录

4. 保留所有其他选项为默认值



![image-20201118162511632](/Users/wjianye/Desktop/BeamOnKDA/image/image-20201118162511632.png)



1. 设置“ Buffer Interval”为“ 60”秒

2. 通过选择*GZIP* 来启用 **S3 compression**，以优化Amazon S3中的数据存储。在压缩之前应用缓冲区大小。结果，如果选择压缩数据，则S3存储桶中对象的大小可以小于您指定的缓冲区大小。

3. 确保选择**Created or update IAM Role**，以便Kinesis Data Firehose使用正确的操作权限。

4. 将所有其他值保留为默认值。

5. 选择**下一步**以移至*查看*屏幕。



![image-20201118164434653](/Users/wjianye/Desktop/BeamOnKDA/image/image-20201118164434653.png)



### REVIEW SETTINGS

检查完所有设置后，选择“创建传送流”以创建Firehose传送流。几分钟后，您将在Kinesis仪表板上看到一个名为beam-workshop-s3的Firehose交付流。单击流名称以查看更多详细信息，并在以后的阶段中使用此页面监视活动。

![image-20201118170703721](/Users/wjianye/Desktop/BeamOnKDA/image/image-20201118170703721.png)



